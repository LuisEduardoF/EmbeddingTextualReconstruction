# AnÃ¡lise de Riscos de ReconstruÃ§Ã£o Textual em Modelos de PrediÃ§Ã£o de ConciliaÃ§Ã£o Trabalhista

## ğŸ“‹ VisÃ£o Geral

Este projeto investiga vulnerabilidades de seguranÃ§a em sistemas de InteligÃªncia Artificial aplicados ao JudiciÃ¡rio brasileiro, especificamente analisando riscos de **inversÃ£o de embeddings** em modelos de prediÃ§Ã£o de conciliaÃ§Ãµes trabalhistas baseados em BERT.

## ğŸ¯ Problema e MotivaÃ§Ã£o

O JudiciÃ¡rio brasileiro tem adotado tÃ©cnicas de InteligÃªncia Artificial e Processamento de Linguagem Natural (PLN), utilizando modelos como BERTimbau para anÃ¡lise de processos trabalhistas. Embora as representaÃ§Ãµes vetoriais (embeddings) sejam frequentemente consideradas "seguras" por serem numÃ©ricas, este trabalho investiga se esses vetores retÃªm informaÃ§Ãµes semÃ¢nticas suficientes para permitir:

- **ReconstruÃ§Ã£o do texto original** a partir dos embeddings
- **InferÃªncia de atributos sensÃ­veis** atravÃ©s de ataques de inversÃ£o
- **Vazamento de informaÃ§Ãµes confidenciais** na fase de inferÃªncia

### Contexto de AplicaÃ§Ã£o

- **InstituiÃ§Ã£o**: Tribunal Regional do Trabalho (TRT)
- **DomÃ­nio**: PrediÃ§Ã£o de aÃ§Ãµes trabalhistas
- **Modelo Base**: BERTimbau (BERT em portuguÃªs)
- **Foco de SeguranÃ§a**: Confidencialidade dos dados e privacidade em sistemas inteligentes

## ğŸ“ Objetivos

### Objetivo Geral

Avaliar experimentalmente a seguranÃ§a dos embeddings gerados pelo modelo BERTimbau fine-tuned, verificando a viabilidade de recuperar informaÃ§Ãµes textuais de processos judiciais a partir apenas de suas representaÃ§Ãµes vetoriais.

### Produtos Esperados

1. **Modelo Atacante**: Decodificador neural treinado para reverter embeddings em texto
2. **RelatÃ³rio de Auditoria**: QuantificaÃ§Ã£o da taxa de sucesso na recuperaÃ§Ã£o de tokens e palavras-chave sensÃ­veis
3. **AnÃ¡lise de Risco**: AvaliaÃ§Ã£o sobre a suficiÃªncia da anonimizaÃ§Ã£o prÃ©via e correlaÃ§Ãµes semÃ¢nticas perigosas

## ğŸ”¬ Metodologia

### Tipo de Trabalho

**Desenvolvimento Experimental / ProtÃ³tipo**

Este trabalho aproveita o pipeline tÃ©cnico jÃ¡ desenvolvido em TCC anterior, adicionando uma camada adversÃ¡ria para validaÃ§Ã£o prÃ¡tica dos riscos de seguranÃ§a.

### Pipeline de Ataque

```
Texto Original â†’ BERTimbau â†’ Embedding [CLS] â†’ Modelo Atacante â†’ Texto ReconstruÃ­do
                  (Fine-tuned)                    (Inversor)
```

## ğŸ“Š Atividades do Projeto

### 1. GeraÃ§Ã£o de Embeddings
- UtilizaÃ§Ã£o do pipeline de prÃ©-processamento existente
- ExtraÃ§Ã£o de embeddings do token `[CLS]` usando BERTimbau fine-tuned
- CriaÃ§Ã£o de dataset intermediÃ¡rio: `(Vetor Embedding) â†’ (Texto Original)`

### 2. Desenvolvimento do Modelo AdversÃ¡rio
- ImplementaÃ§Ã£o de rede neural "atacante"
- Arquitetura projetada para reconstruÃ§Ã£o textual a partir de embeddings
- PrediÃ§Ã£o de termos sensÃ­veis (ex: nomes de litigantes, doenÃ§as ocupacionais)

### 3. ExecuÃ§Ã£o do Ataque de InversÃ£o
- Treinamento do modelo adversÃ¡rio
- Uso de divisÃ£o temporal consistente com o projeto original
- SimulaÃ§Ã£o de vazamento de dados em condiÃ§Ãµes realistas

### 4. AnÃ¡lise de Vulnerabilidade
- ComparaÃ§Ã£o entre texto reconstruÃ­do e original
- CÃ¡lculo de mÃ©tricas de vazamento de informaÃ§Ã£o
- AvaliaÃ§Ã£o quantitativa da eficÃ¡cia do ataque

### 5. ConsolidaÃ§Ã£o e DocumentaÃ§Ã£o
- RelatÃ³rio final conectando resultados aos conceitos de confidencialidade e privacidade em IA
- RecomendaÃ§Ãµes de seguranÃ§a para sistemas judiciais

## ğŸ“… Cronograma

| Checkpoint | Data | EntregÃ¡vel |
|------------|------|------------|
| **Checkpoint 1** | 21/11 | ApresentaÃ§Ã£o do Conceito + RevisÃ£o da Literatura |
| **Checkpoint 2** | 18/12 | DefiniÃ§Ã£o da Arquitetura do Modelo Atacante + Resultados Parciais |
| **Checkpoint 3** | 05/05 | CÃ³digo Completo + RelatÃ³rio Final + Resultados |

## ğŸ” TÃ³picos de SeguranÃ§a Abordados

- **Privacidade em Sistemas Inteligentes**
- **Vazamentos e Rastreabilidade de Dados**
- **Confidencialidade na Fase de InferÃªncia**
- **Ataques de InversÃ£o de Modelo**
- **Vulnerabilidades em RepresentaÃ§Ãµes Vetoriais**

## ğŸ“š Conceitos-Chave

- **Embeddings**: RepresentaÃ§Ãµes vetoriais densas de texto
- **Token [CLS]**: Token especial do BERT usado para classificaÃ§Ã£o
- **InversÃ£o de Modelo**: TÃ©cnica adversÃ¡ria para recuperar dados de entrada a partir de saÃ­das do modelo
- **BERTimbau**: VersÃ£o do BERT prÃ©-treinada em portuguÃªs brasileiro
- **Fine-tuning**: Ajuste fino de modelo prÃ©-treinado para tarefa especÃ­fica

## ğŸ› ï¸ Tecnologias

- **Modelo Base**: BERTimbau
- **Framework**: PyTorch / TensorFlow
- **Linguagem**: Python
- **DomÃ­nio**: Processamento de Linguagem Natural (PLN)
- **Ãrea**: SeguranÃ§a em Machine Learning

## ğŸ“– Estrutura do RepositÃ³rio

```
.
â”œâ”€â”€ README.md                 # Este arquivo
â”œâ”€â”€ data/                     # Dados e embeddings
â”œâ”€â”€ models/                   # Modelos treinados
â”‚   â”œâ”€â”€ bertimbau/           # Modelo BERTimbau fine-tuned
â”‚   â””â”€â”€ attacker/            # Modelo adversÃ¡rio (inversor)
â”œâ”€â”€ src/                      # CÃ³digo fonte
â”‚   â”œâ”€â”€ preprocessing/       # Pipeline de prÃ©-processamento
â”‚   â”œâ”€â”€ embedding/           # GeraÃ§Ã£o de embeddings
â”‚   â”œâ”€â”€ attack/              # ImplementaÃ§Ã£o do ataque
â”‚   â””â”€â”€ evaluation/          # MÃ©tricas e anÃ¡lises
â”œâ”€â”€ notebooks/               # Jupyter notebooks para anÃ¡lise
â”œâ”€â”€ results/                 # Resultados e visualizaÃ§Ãµes
â””â”€â”€ docs/                    # DocumentaÃ§Ã£o adicional
```

## ğŸ¯ ContribuiÃ§Ãµes Esperadas

1. **CientÃ­fica**: EvidÃªncias empÃ­ricas sobre riscos de privacidade em embeddings de modelos jurÃ­dicos
2. **PrÃ¡tica**: Metodologia de auditoria de seguranÃ§a para sistemas de IA no JudiciÃ¡rio
3. **TÃ©cnica**: ImplementaÃ§Ã£o de modelo adversÃ¡rio para inversÃ£o de embeddings BERT

## âš ï¸ ConsideraÃ§Ãµes Ã‰ticas

Este trabalho Ã© conduzido com propÃ³sitos de pesquisa em seguranÃ§a, visando:
- Identificar vulnerabilidades antes de exploraÃ§Ã£o maliciosa
- Propor medidas de proteÃ§Ã£o para dados sensÃ­veis
- Contribuir para o desenvolvimento responsÃ¡vel de IA no sistema judiciÃ¡rio

## ğŸ“„ LicenÃ§a

[Definir licenÃ§a apropriada]

## ğŸ‘¥ Autores

[Adicionar informaÃ§Ãµes dos autores]

## ğŸ“§ Contato

[Adicionar informaÃ§Ãµes de contato]

---

**Nota**: Este projeto faz parte de trabalho acadÃªmico na Ã¡rea de SeguranÃ§a em Sistemas Inteligentes, com foco em privacidade e confidencialidade de dados judiciais.